% !TeX spellcheck = en_US

%
% This is a borrowed LaTeX template file for lecture notes for CS267,
% Applications of Parallel Computing, UCBerkeley EECS Department.
% Now being used for CMU's 10725 Fall 2012 Optimization course
% taught by Geoff Gordon and Ryan Tibshirani.  When preparing 
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi. "pdflatex template.tex" should also work.
%

\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%
\usepackage{graphicx}
\usepackage{amsmath,amsfonts,graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lipsum}
 \usepackage[margin=1in]{geometry} 
\usepackage{amsthm,amssymb}
\usepackage{bm}

\usepackage{booktabs}
%\renewcommand{\familydefault}{pag}
%\renewcommand{\familydefault}{pbk}
% https://en.wikibooks.org/wiki/LaTeX/Fonts

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[7]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf Machine Learning
	\hfill Spring 2017} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Solution : #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill Homework taker: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Solution : #2}{Solution : #2}
}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newenvironment{problem}[2][Problem]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
%\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}
\newenvironment{solution}{{\bf Solution:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand\E{\mathbb{E}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{3}{Homework 4}{Yang Yang}{Li Xu}



 % \textbf{Notification:} You can take 5 problems randomly from all of 15 problems except the problem you design.
  \textbf{Due Time:}June 9

\begin{problem}{1}
\end{problem}

\begin{solution}

\emph{Answer for problem (1):}

We have
$$
S = \frac{XX^T}{N}
$$
As $S$ is symmetric, it can be diagonalized:
$$
S = ULU^T
$$
where $U$ is a matrix of eigenvectors($U$ = \{$u_i$\}).

If 
$$
X = US'V^T
$$

Then
$$
S = U\frac{S'^2}{N}U^T
$$
i.e. The principal components \{$u_i$\} are columns of $U$.

\emph{Answer for problem (2):}

SVD is better as $XX^T$ can be very large if D $>>$ N

\end{solution}

\begin{problem}{2}
\end{problem} 
\begin{solution}
	
	\emph{Answer for problem (a):}

	i. roads salted, school cancellation
	
	ii. none
	
	iii. none
	
	iv. temperature
	
	\emph{Answer for problem (b):}

	
	\begin{multline*}
	p(\mathbf{temperature, snow, roads\ salted, school\ cancellation}) = \\ p(\mathbf{temperature})p(\mathbf{snow|temperature})p(\mathbf{roads\ salted|snow})\\
	p(\mathbf{school\ cancellation|roads\ salted, snow})
	\end{multline*}
	
	
	\emph{Answer for problem (c):}	
	\begin{align*}
	p(\mathbf{snow} = light) &= \sum_{\mathbf{temperature}}p(\mathbf{temperature})p(\mathbf{snow} = light|\mathbf{temperature}) \\
	&= 0.208
	\end{align*}
	\begin{align*}
	p(\mathbf{roads\ salted} = T, \mathbf{snow} = light) &= p(\mathbf{roads\ salted} = T| \mathbf{snow} = light) * p(\mathbf{snow} = light) \\
	&= 0.1872
	\end{align*}
	\begin{align*}
	p(\mathbf{roads\ salted} = F, \mathbf{snow} = light) &= p(\mathbf{roads\ salted} = F| \mathbf{snow} = light) * p(\mathbf{snow} = light) \\
	&= 0.0208
	\end{align*}
	\begin{align*}
	p(\mathbf{school\ cancellation} = T| \mathbf{snow} = light) = \frac{p(\mathbf{school\ cancellation} = T, \mathbf{snow} = light)}{p( \mathbf{snow} = light)} \\
	= \frac{\sum_{\mathbf{roads\ salted}}p(\mathbf{school\ cancellation} = T, \mathbf{snow} = light, \mathbf{roads\ salted})}{p( \mathbf{snow} = light)} \\
	= 0.22
	\end{align*}
	\begin{align*}
	p(\mathbf{school\ cancellation} = F| \mathbf{snow} = light) = 1 - p(\mathbf{school\ cancellation} = T| \mathbf{snow} = light) = 0.78
	\end{align*}
	
\end{solution}

\begin{problem}{3}
\end{problem} 
\begin{solution}

\emph{Answer for problem (a):}

\begin{align*}
\mathit{l}(\theta^{(t+1)}) &>= \sum_i \sum_{z^{(i)}}Q_i^{(t)}(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta^{(t+1)})}{Q_i^{(t)}(z^{(i)})} \\
&>= \sum_i \sum_{z^{(i)}}Q_i^{(t)}(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta^{(t)})}{Q_i^{(t)}(z^{(i)})} \\
&=\mathit{l}(\theta^{(t)})
\end{align*}

\emph{Answer for problem (b):}

Differentiating the log likelihood directly we get
\begin{align*}
\frac{\partial}{\partial\theta_j}\sum_i\log\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta) &= \sum_i\frac{1}{\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta)}\sum_{z^{(i)}}\frac{\partial}{\partial\theta_j}p(x^{(i)},z^{(i)};\theta) \\
&= \sum_i\sum_{z^{(i)}}\frac{1}{p(x^{(i)};\theta)}\cdot\frac{\partial}{\partial\theta_j}p(x^{(i)},z^{(i)};\theta)
\end{align*}

For the GEM algorithm,
$$
\frac{\partial}{\partial\theta_j}\sum_i\sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} = \sum_i\sum_{z^{(i)}}\frac{Q_i(z^{(i)})}{p(x^{(i)},z^{(i)};\theta)}\cdot\frac{\partial}{\partial\theta_j}p(x^{(i)},z^{(i)};\theta)
$$

But for E-step of the GEM algorithm chooses
$$
Q_i(z^{(i)}) = p(x^{(i)}|z^{(i)};\theta) = \frac{p(x^{(i)},z^{(i)};\theta)}{p(x^{(i)};\theta)}
$$

So
$$
\sum_i\sum_{z^{(i)}}\frac{Q_i(z^{(i)})}{p(x^{(i)},z^{(i)};\theta)}\cdot\frac{\partial}{\partial\theta_j}p(x^{(i)},z^{(i)};\theta) = \sum_i\sum_{z^{(i)}}\frac{1}{p(x^{(i)};\theta)}\cdot\frac{\partial}{\partial\theta_j}p(x^{(i)},z^{(i)};\theta)
$$
which is the same as the derivative of the log likelihood.3
\end{solution}
\end{document}